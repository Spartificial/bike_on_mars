{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bigger-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "from decimal import Decimal\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bicycle and its environment\n",
    "\n",
    "class CycleBalancingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}  \n",
    "  \n",
    "    def __init__(self):\n",
    "        # Out cycle has only 2 action spaces i.e. Torque of the wheels and the position of the handlebar\n",
    "        self.action_space = gym.spaces.box.Box(\n",
    "            low=-1 * np.ones(1, dtype=np.float32),\n",
    "            high=1 * np.ones(1, dtype=np.float32))\n",
    "        \n",
    "        # Obervation space\n",
    "        self.observation_space = gym.spaces.box.Box(\n",
    "            low=-1 * np.ones(24, dtype=np.float32),\n",
    "            high=1 * np.ones(24, dtype=np.float32))\n",
    "        \n",
    "        self.np_random, _ = gym.utils.seeding.np_random()\n",
    "\n",
    "        if not p.isConnected():\n",
    "            self.client = p.connect(p.GUI) # Physics + Visual\n",
    "            #self.client = p.connect(p.DIRECT) # Only Physics, no visualization. For faster training\n",
    "        else:\n",
    "            self.client = 1\n",
    "        \n",
    "        self.n_target = 200 #Number of obstacles\n",
    "        self.min_target_dist = 5 #Minimum distance of obstacles from bike\n",
    "        self.target_span = 100 #Maximum distance of obstacles from bike\n",
    "        self.sphere_dist = 1.5\n",
    "        #self.pole = []\n",
    "        \n",
    "        p.resetSimulation(self.client)\n",
    "        p.setRealTimeSimulation(0)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        \n",
    "        self.plane=p.loadURDF(\"plane.urdf\",[0,0,0], useFixedBase=True) #Loading the Plane Surface\n",
    "        self.bike = 0 #Index of the Bike\n",
    "        self.angle_span = 20 #The Angle between two consecutive rays\n",
    "        self.n_episodes = 0 #Count of the number of episodes\n",
    "        self.rays_distance = 30 #The max length of the rays\n",
    "        self.z_balance = -0.25 #Offset between the Bike's center of gravity and the height from which rays are passed\n",
    "        \n",
    "        self.make_obstacles() #create the obstacles\n",
    "        self.reset() #Reseting the environment\n",
    "        \n",
    "        \n",
    "    #Helper (Debugger) function to show the distance traveled by rays in all direction\n",
    "    def show_img(self):\n",
    "        \n",
    "        self.img = np.zeros((800,800,3), dtype='float32')\n",
    "        shift = 400\n",
    "        multiply = 400\n",
    "        ls = p.getBasePositionAndOrientation(self.bike)\n",
    "        bike_x = ls[0][0]\n",
    "        bike_y = ls[0][1]\n",
    "        handlebar_rotation = p.getEulerFromQuaternion( p.getLinkState(self.bike, 0)[1] )[2]\n",
    "        mini = 1000\n",
    "        for deg in range(1, 361, 1):\n",
    "            mini = min(mini, self.dist[deg-1])\n",
    "            if deg%self.angle_span==0:\n",
    "                rad = Decimal( Decimal(deg * np.pi/180 + handlebar_rotation)%Decimal(2*np.pi) + Decimal(2*np.pi))%Decimal(2*np.pi)\n",
    "                rad = float(rad)\n",
    "                start = (int(shift + bike_x + self.sphere_dist*np.cos(rad)), int(shift + bike_y + self.sphere_dist*np.sin(rad)))\n",
    "                end = (int(shift + bike_x + mini*multiply*np.cos(rad)), int(shift + bike_y + mini*multiply*np.sin(rad)))\n",
    "                cv2.ellipse(self.img, start, (int(mini*multiply),int(mini*multiply)), 0, (rad*180/np.pi)-self.angle_span, (rad*180/np.pi), (0,0,255), -1)\n",
    "                mini = 1000\n",
    "            \n",
    "        cv2.imshow('img', cv2.rotate(cv2.transpose(self.img), cv2.ROTATE_180))\n",
    "        #cv2.imshow('img', self.img)\n",
    "        cv2.waitKey(1)\n",
    "        #cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "    def apply_action(self, action):\n",
    "        p.setJointMotorControl2(self.bike, 0, p.POSITION_CONTROL, targetPosition=action[0], maxVelocity=5) # Apply Position control to Handlebar\n",
    "    \n",
    "    \n",
    "    def apply_torque_wheels(self):\n",
    "        p.setJointMotorControl2(self.bike,1,p.TORQUE_CONTROL , force=(2.5+0)*10000) # Apply Toruqe to Back Wheel\n",
    "        p.setJointMotorControl2(self.bike,2,p.TORQUE_CONTROL , force=(2.5+0)*10000) # Apply Toruqe to Front Wheel\n",
    "        \n",
    "        \n",
    "    def gyroscope_torque(self):\n",
    "        ls = p.getBasePositionAndOrientation(self.bike) # ls[0]=Postion of cycle, ls[1] = Orientation of cycle\n",
    "        val = p.getEulerFromQuaternion(ls[1])[0] - 1.57 # Calculating inclination of cycle from vertical\n",
    "        p.applyExternalTorque(self.bike, -1, [-1000000*val, 0, 0], flags=p.WORLD_FRAME)\n",
    "\n",
    "        \n",
    "    def add_pos_orien(self):\n",
    "        ls = p.getBasePositionAndOrientation(self.bike) #Calculating the postion and orientation of the Bike\n",
    "        # ls[0]=Postion of cycle, ls[1] = Orientation of cycle\n",
    "        self.obs += ls[0] #Adding postion\n",
    "        self.obs += p.getEulerFromQuaternion(ls[1]) #Adding orientation\n",
    "        \n",
    "    \n",
    "    def add_dist_by_rays(self):\n",
    "        ls = p.getBasePositionAndOrientation(self.bike) #Calculating the postion and orientation of the Bike\n",
    "            \n",
    "        z = ls[0][2] + self.z_balance #Height of the bike above the ground (Used by rays)\n",
    "            \n",
    "        self.bike_x = ls[0][0] #X-position of the Bike\n",
    "        self.bike_y = ls[0][1] #Y-position of the Bike\n",
    "        \n",
    "        #Calculating the positon and length of the rays (i.e. start and end points of the rays)\n",
    "        bike_x = ls[0][0]\n",
    "        bike_y = ls[0][1]\n",
    "        reward_2 = 0\n",
    "        ray_from = []\n",
    "        ray_to = []\n",
    "        handlebar_rotation = p.getEulerFromQuaternion( p.getLinkState(self.bike, 0)[1] )[2]\n",
    "        for deg in range(1, 361, 1):\n",
    "            rad = Decimal( Decimal(deg * np.pi/180 + handlebar_rotation)%Decimal(2*np.pi) + Decimal(2*np.pi))%Decimal(2*np.pi)\n",
    "            rad = float(rad)\n",
    "            for i in np.arange(0, 3, 1):\n",
    "                for j in np.arange(-4, 1, 0.5):\n",
    "                    ray_from.append((bike_x + self.sphere_dist*np.cos(rad), bike_y + self.sphere_dist*np.sin(rad), z+i))\n",
    "                    ray_to.append((bike_x + self.rays_distance*np.cos(rad), bike_y + self.rays_distance*np.sin(rad), z+j))\n",
    "        \n",
    "        #Adding the observation of the rays (i.e whether the rays collided with any object or not)\n",
    "        rays = p.rayTestBatch(ray_from, ray_to)\n",
    "        mini = 1000\n",
    "        self.dist = []\n",
    "        mini = 1000\n",
    "        cnt = 0\n",
    "        for deg in range(1, 361, 1):\n",
    "            dist = 1\n",
    "            for i in np.arange(0, 3, 1):\n",
    "                for j in np.arange(-4, 1, 0.5):\n",
    "                    tmp = rays[cnt]\n",
    "                    cnt += 1\n",
    "                    if tmp[0]!=self.plane: dist = min(dist, tmp[2])\n",
    "            if dist<mini:\n",
    "                mini = dist\n",
    "            self.dist.append(dist)\n",
    "            if deg%self.angle_span==0:\n",
    "                self.obs.append(mini)\n",
    "                mini = 1000\n",
    "\n",
    "    \n",
    "    def get_collision(self):\n",
    "        ls = p.getContactPoints(self.bike)\n",
    "        reward = 0\n",
    "        done = False\n",
    "        for i in range(len(ls)):\n",
    "            if ls[i][2]!=0:\n",
    "                reward = -100\n",
    "                done = True\n",
    "        return reward, done\n",
    "    \n",
    "    def prevent_rotating_in_a_cycle(self):\n",
    "        ls = p.getBasePositionAndOrientation(self.bike) #Calculating the postion and orientation of the Bike\n",
    "        value = p.getEulerFromQuaternion(p.getLinkState(self.bike, 0)[1])[2] - p.getEulerFromQuaternion(ls[1])[2]\n",
    "        if value<-1: value += 2*np.pi\n",
    "        if value>1: value -= 2*np.pi\n",
    "        #print(value)\n",
    "        if value < -0.5:\n",
    "            self.left += 0.1\n",
    "            self.right = 0\n",
    "        elif value > 0.5:\n",
    "            self.left = 0\n",
    "            self.right += 0.1\n",
    "        else:\n",
    "            self.left = 0\n",
    "            self.right = 0\n",
    "            \n",
    "        self.neg_reward = 0\n",
    "        if self.left>10 or self.right>10:\n",
    "            print(\"Slow!!!\")\n",
    "            self.neg_reward = -100\n",
    "            self.done = True\n",
    "            \n",
    "    def target_dist_achieved(self):\n",
    "        reward_1 = 0\n",
    "        dist_2 = np.sqrt((self.bike_x)**2 + abs(self.bike_y)**2)\n",
    "        if dist_2 > self.target_dist:\n",
    "            reward_1 = 100 + self.target_reward\n",
    "            self.target_dist += 10\n",
    "            self.target_reward = min(500, self.target_reward*2)\n",
    "            \n",
    "        self.completed = 0\n",
    "        if dist_2 > self.target_span:\n",
    "            self.completed = 1\n",
    "            self.done = True\n",
    "            print(\"DONE!\")\n",
    "            self.make_obstacles()\n",
    "        return reward_1\n",
    "    \n",
    "    def get_reward(self, reward_1, reward_2):\n",
    "        dist_2 = np.sqrt((self.bike_x)**2 + abs(self.bike_y)**2)\n",
    "        if self.time%10==0 and dist_2>self.distance: \n",
    "            self.distance = dist_2\n",
    "        return reward_1 + reward_2 + max(-10, (dist_2-self.distance)) + self.time/1000 + self.neg_reward - self.left - self.right\n",
    "    \n",
    "    def get_obs(self):\n",
    "        #For storing all the observations which will be used by the agent to decide the next action\n",
    "        self.obs = [] \n",
    "        \n",
    "        #Add bike's position, orientation to the observation space\n",
    "        self.add_pos_orien() \n",
    "        \n",
    "        #Add info from rays to the observation space (i.e whether rays collided with ant object or not)\n",
    "        self.add_dist_by_rays()\n",
    "        \n",
    "        self.obs = np.array(self.obs, dtype=np.float32)\n",
    "        self.obs[0] /= self.target_span\n",
    "        self.obs[1] /= self.target_span\n",
    "        \n",
    "                \n",
    "    #Step function\n",
    "    def step(self, action):\n",
    "        \n",
    "        self.apply_action(action)\n",
    "        \n",
    "        for i in range(3):\n",
    "            self.apply_torque_wheels() #Apply Torque to the wheels (i.e increase velocity)\n",
    "            self.gyroscope_torque()#Balancing by applying Torque (In real world, this will be done by gyroscope) \n",
    "            p.stepSimulation()\n",
    "            \n",
    "        self.get_obs() #Get the observation\n",
    "        \n",
    "        #Terminate the episode if the Bike collided with any obstacle\n",
    "        reward_2, self.done = self.get_collision() \n",
    "    \n",
    "        # Adding 1 to the time for which the current episode has been running\n",
    "        self.time += 1 \n",
    "                \n",
    "        #Terminate the episode if the Bike keeps rotating in a circle\n",
    "        self.prevent_rotating_in_a_cycle() \n",
    "            \n",
    "        # Terminating the episode if the cycle is more than \"target_span\" distance away from the origin\n",
    "        reward_1 = self.target_dist_achieved()\n",
    "        \n",
    "        # Calculating the total reward\n",
    "        reward = self.get_reward(reward_1, reward_2)\n",
    "\n",
    "        return self.obs, reward/100, self.done, dict()\n",
    "\n",
    "\n",
    "    def load_bike(self):\n",
    "        #Remove the Bike if already loaded\n",
    "        if self.bike!=0:\n",
    "            p.removeBody(self.bike)\n",
    "            \n",
    "        # Loading the Bike\n",
    "        self.bike_x = 0 # random.randint(-5, 5) # X position of the Bike\n",
    "        self.bike_y = 0 # random.randint(-5, 5) # Y position of the Bike\n",
    "        #path = os.getcwd()\n",
    "        self.bike=p.loadURDF('bike_2.urdf.xml',[self.bike_x, self.bike_y,0], p.getQuaternionFromEuler([0,0, random.random()*2*np.pi]),  useFixedBase=False)\n",
    "        \n",
    "    def add_dynamics(self):\n",
    "        # Adding friction and other dynamics\n",
    "        p.changeDynamics(self.plane, -1, lateralFriction=5, angularDamping=1)\n",
    "        p.changeDynamics(self.bike, 1, mass=100)\n",
    "        p.changeDynamics(self.bike, -1, lateralFriction=5, angularDamping=1)\n",
    "        \n",
    "        p.setGravity(0, 0, -250) # Setting the gravity\n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        self.n_episodes += 1 #Increase the number of episodes by 1\n",
    "        \n",
    "        #Change obstacles's position after every 20 episodes for robust training\n",
    "        if self.n_episodes==20:\n",
    "            self.make_obstacles()\n",
    "            self.n_episodes = 0\n",
    "        \n",
    "        self.load_bike()\n",
    "        \n",
    "        for i in range(10):\n",
    "            p.stepSimulation()\n",
    "        \n",
    "        self.add_dynamics()\n",
    "        \n",
    "        self.done=False\n",
    "        self.time = 0\n",
    "        self.distance = np.sqrt((self.bike_x)**2 + abs(self.bike_y)**2)\n",
    "        self.neg_reward = 0\n",
    "        \n",
    "        self.get_obs() #Get the observation\n",
    "        \n",
    "        #Initialize variables\n",
    "        self.cnt = 0\n",
    "        self.left = 0\n",
    "        self.right = 0\n",
    "        self.target_dist = 10\n",
    "        self.target_reward = 32\n",
    "        self.completed = 0\n",
    "        \n",
    "        return self.obs\n",
    "\n",
    "    #Function to create the obstacles\n",
    "    def make_obstacles(self):\n",
    "        \n",
    "        p.resetSimulation(self.client)\n",
    "        p.setRealTimeSimulation(0)\n",
    "        #p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        \n",
    "        #Load the obstacles\n",
    "        mul = 100 #Factor to increase or decrease the size of the obstacles\n",
    "        height = 2\n",
    "        visualShift = [0, 0, 0]\n",
    "        shift = [0, 0, 0]\n",
    "        meshScale=[0.1*mul, 0.1*mul, 0.1*mul*height]\n",
    "        #path = 'C:/Users/User/Documents/GitHub/bullet3/examples/pybullet/gym/pybullet_data/'\n",
    "        groundColId = p.createCollisionShape(shapeType=p.GEOM_MESH, \n",
    "                                                  fileName=\"terrain.obj\", \n",
    "                                                  collisionFramePosition=shift,\n",
    "                                                  meshScale=meshScale,\n",
    "                                                  flags=p.GEOM_FORCE_CONCAVE_TRIMESH)\n",
    "        groundVisID = p.createVisualShape(shapeType=p.GEOM_MESH, \n",
    "                                            fileName=\"terrain.obj\", \n",
    "                                            rgbaColor=[0.7,0.3,0.1,1],\n",
    "                                            specularColor=[0.4,.4,0],\n",
    "                                            visualFramePosition=visualShift,\n",
    "                                            meshScale=meshScale)\n",
    "        self.plane = p.createMultiBody(baseMass=0,\n",
    "                                              baseInertialFramePosition=[0,0,0],\n",
    "                                              baseCollisionShapeIndex=groundColId, \n",
    "                                              baseVisualShapeIndex=groundVisID, \n",
    "                                              basePosition=[0,0,0], \n",
    "                                              useMaximalCoordinates=True)\n",
    "        \n",
    "        self.bike = 0\n",
    "        self.bike_x = 0\n",
    "        self.bike_y = 0\n",
    "        self.pole = []\n",
    "        # Load the Target\n",
    "        for i in range(self.n_target):\n",
    "            target_x = self.bike_x\n",
    "            target_y = self.bike_y\n",
    "            while (np.sqrt( (self.bike_x - target_x)**2 + (self.bike_y - target_y)**2 )) < self.min_target_dist:\n",
    "                target_x = random.randint(int(self.bike_x) - self.target_span, int(self.bike_x) + self.target_span)\n",
    "                target_y = random.randint(int(self.bike_y) - self.target_span, int(self.bike_y) + self.target_span)\n",
    "            self.pole.append( p.loadURDF(\"cube.urdf\", [target_x, target_y, 4], [0,0,0,1], useFixedBase=True, globalScaling=1.0) )\n",
    "            p.changeDynamics(self.pole[i], -1, mass=1000)\n",
    "            \n",
    "    \n",
    "    #Render the output Visual\n",
    "    def render(self, mode='human'): \n",
    "        distance=5\n",
    "        yaw = 0\n",
    "        humanPos, humanOrn = p.getBasePositionAndOrientation(self.bike)\n",
    "        humanBaseVel = p.getBaseVelocity(self.bike)\n",
    "        #print(\"frame\",frame, \"humanPos=\",humanPos, \"humanVel=\",humanBaseVel)\n",
    "        camInfo = p.getDebugVisualizerCamera()\n",
    "        curTargetPos = camInfo[11]\n",
    "        distance=camInfo[10]\n",
    "        yaw = camInfo[8]\n",
    "        pitch=camInfo[9]\n",
    "        targetPos = [0.95*curTargetPos[0]+0.05*humanPos[0],0.95*curTargetPos[1]+0.05*humanPos[1],curTargetPos[2]]\n",
    "        \n",
    "        p.resetDebugVisualizerCamera(distance,270 ,pitch,targetPos)\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect(self.client)\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
    "        return [seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "consecutive-chicago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the environment\n",
    "env = CycleBalancingEnv()\n",
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worst-horror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space =  (24,)\n",
      "Sample Action =  [0.6655078]\n"
     ]
    }
   ],
   "source": [
    "print('Observation space = ', env.observation_space.sample().shape)\n",
    "print('Sample Action = ', env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intense-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n",
      "Episode:1 Score:50.768000176974795\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        action = [0.]\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "        time.sleep(1/240.)\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "transparent-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "empirical-classic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24,), 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = env.observation_space.shape # Shape of our observation space\n",
    "nb_actions = env.action_space.shape[0] # shape of our action space\n",
    "states, nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ideal-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del actor, critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "complex-cathedral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                800       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,945\n",
      "Trainable params: 2,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defining our actor model for the DDPG algorithm\n",
    "\n",
    "actor = Sequential()\n",
    "actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "actor.add(Dense(32, kernel_initializer='he_uniform'))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(32, kernel_initializer='he_uniform'))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(32, kernel_initializer='he_uniform'))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('tanh'))\n",
    "print(actor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "million-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  [(None, 1, 24)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 24)           0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 25)           0           action_input[0][0]               \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           832         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           1056        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           1056        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            33          activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1)            0           dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,977\n",
      "Trainable params: 2,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defining our critic network for the DDPG algorithm\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = tf.keras.Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = Concatenate()([action_input, flattened_observation])\n",
    "x = Dense(32, kernel_initializer='he_uniform')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32, kernel_initializer='he_uniform')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32, kernel_initializer='he_uniform')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = tf.keras.Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pursuant-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from rl.agents import DQNAgent, SARSAAgent, DDPGAgent\n",
    "#from rl.agents.sarsa import SARSAAgent\n",
    "from rl.policy import BoltzmannQPolicy, BoltzmannGumbelQPolicy, SoftmaxPolicy,  EpsGreedyQPolicy, GreedyQPolicy, BoltzmannGumbelQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "from rl.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minute-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_reward = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "amazing-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "from rl.core import Agent\n",
    "from rl.policy import Policy\n",
    "from rl.util import *\n",
    "\n",
    "\n",
    "def mean_q(y_true, y_pred):\n",
    "    return K.mean(K.max(y_pred, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "skilled-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "from rl.core import Agent\n",
    "from rl.policy import Policy\n",
    "from rl.util import *\n",
    "\n",
    "\n",
    "def mean_q(y_true, y_pred):\n",
    "    return K.mean(K.max(y_pred, axis=-1))\n",
    "\n",
    "class DDPGAgent(Agent):\n",
    "    \"\"\"\n",
    "    # Arguments\n",
    "        nb_actions: Number of actions\n",
    "        actor, critic: Keras models\n",
    "        critic_action_input: input layer in critic model that corresponds to actor output\n",
    "        enable_twin_delay: enable Twin Delayed DDPG\n",
    "        random_process: noise to add to actor during training when agent performs forward pass\n",
    "        policy_delay: how many steps to delay policy updates by wrt critic updates\n",
    "        noise_sigma: noise to add to actor during training when agent performs backward pass, for critic policy update (TD3)\n",
    "        noise_clip: value to clip above noise by (TD3)\n",
    "    \"\"\"\n",
    "    def __init__(self, nb_actions, actor, critic, critic_action_input, memory,\n",
    "                 gamma=.99, batch_size=32, nb_steps_warmup_critic=1000, nb_steps_warmup_actor=1000,\n",
    "                 train_interval=1, memory_interval=1, delta_range=None, delta_clip=np.inf,\n",
    "                 random_process=None, custom_model_objects={}, target_model_update=.001,\n",
    "                 policy=None, enable_twin_delay=False, policy_delay=None, noise_clip=0.5,\n",
    "                 noise_sigma=0.2, **kwargs):\n",
    "\n",
    "        super(DDPGAgent, self).__init__(**kwargs)\n",
    "\n",
    "        # Soft vs hard target model updates.\n",
    "        if target_model_update < 0:\n",
    "            raise ValueError('`target_model_update` must be >= 0.')\n",
    "        elif target_model_update >= 1:\n",
    "            # Hard update every `target_model_update` steps.\n",
    "            target_model_update = int(target_model_update)\n",
    "        else:\n",
    "            # Soft update with `(1 - target_model_update) * old + target_model_update * new`.\n",
    "            target_model_update = float(target_model_update)\n",
    "\n",
    "        if delta_range is not None:\n",
    "            warnings.warn('`delta_range` is deprecated. Please use `delta_clip` instead, which takes a single scalar. For now we\\'re falling back to `delta_range[1] = {}`'.format(delta_range[1]))\n",
    "            delta_clip = delta_range[1]\n",
    "\n",
    "        # Parameters.\n",
    "        self.enable_twin_delay = enable_twin_delay\n",
    "        self.nb_actions = nb_actions\n",
    "        self.nb_steps_warmup_actor = nb_steps_warmup_actor\n",
    "        self.nb_steps_warmup_critic = nb_steps_warmup_critic\n",
    "        self.random_process = random_process\n",
    "        self.gamma = gamma\n",
    "        self.target_model_update = target_model_update\n",
    "        self.batch_size = batch_size\n",
    "        self.train_interval = train_interval\n",
    "        self.memory_interval = memory_interval\n",
    "        self.custom_model_objects = custom_model_objects\n",
    "        self.policy_delay = policy_delay\n",
    "        if policy_delay is None:\n",
    "            if self.enable_twin_delay:\n",
    "                self.policy_delay = 2\n",
    "            else:\n",
    "                self.policy_delay = 1\n",
    "        if policy is None:\n",
    "            self.policy = DDPGPolicy()\n",
    "        self.noise_clip = noise_clip\n",
    "        self.noise_sigma = noise_sigma\n",
    "        self.delta_clip = delta_clip\n",
    "\n",
    "        # Related objects.\n",
    "        self.actor = actor\n",
    "        self.critic = critic\n",
    "        self.critic_action_input = critic_action_input\n",
    "        self.critic_action_input_idx = self.critic.input.index(critic_action_input)\n",
    "        self.memory = memory\n",
    "\n",
    "        # State.\n",
    "        self.compiled = False\n",
    "        self.reset_states()\n",
    "\n",
    "    @property\n",
    "    def uses_learning_phase(self):\n",
    "        return self.actor.uses_learning_phase or self.critic.uses_learning_phase\n",
    "\n",
    "    def compile(self, optimizer, metrics=[]):\n",
    "        metrics += [mean_q]\n",
    "\n",
    "        if type(optimizer) in (list, tuple):\n",
    "            if len(optimizer) != 2:\n",
    "                raise ValueError('More than two optimizers provided. Please only provide a maximum of two optimizers, the first one for the actor and the second one for the critic.')\n",
    "            actor_optimizer, critic_optimizer = optimizer\n",
    "        else:\n",
    "            actor_optimizer = optimizer\n",
    "            critic_optimizer = clone_optimizer(optimizer)\n",
    "        if type(actor_optimizer) is str:\n",
    "            actor_optimizer = optimizers.get(actor_optimizer)\n",
    "        if type(critic_optimizer) is str:\n",
    "            critic_optimizer = optimizers.get(critic_optimizer)\n",
    "        assert actor_optimizer != critic_optimizer\n",
    "\n",
    "        if len(metrics) == 2 and hasattr(metrics[0], '__len__') and hasattr(metrics[1], '__len__'):\n",
    "            actor_metrics, critic_metrics = metrics\n",
    "        else:\n",
    "            actor_metrics = critic_metrics = metrics\n",
    "\n",
    "        def clipped_error(y_true, y_pred):\n",
    "            return K.mean(huber_loss(y_true, y_pred, self.delta_clip), axis=-1)\n",
    "\n",
    "        # Compile target networks. We only use them in feed-forward mode, hence we can pass any\n",
    "        # optimizer and loss since we never use it anyway.\n",
    "        self.target_actor = clone_model(self.actor, self.custom_model_objects)\n",
    "        self.target_actor.compile(optimizer='sgd', loss='mse')\n",
    "        self.target_critic = clone_model(self.critic, self.custom_model_objects)\n",
    "        self.target_critic.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "        # We also compile the actor. We never optimize the actor using Keras but instead compute\n",
    "        # the policy gradient ourselves. However, we need the actor in feed-forward mode, hence\n",
    "        # we also compile it with any optimzer and\n",
    "        self.actor.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "        # Compile the critic.\n",
    "        if self.target_model_update < 1.:\n",
    "            # We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.\n",
    "            critic_updates = get_soft_target_model_updates(self.target_critic, self.critic, self.target_model_update)\n",
    "            critic_optimizer = AdditionalUpdatesOptimizer(critic_optimizer, critic_updates)\n",
    "        self.critic.compile(optimizer=critic_optimizer, loss=clipped_error, metrics=critic_metrics)\n",
    "\n",
    "        # Set up second critic network for TD3\n",
    "        if self.enable_twin_delay:\n",
    "            self.critic2 = clone_model(self.critic, self.custom_model_objects)\n",
    "            self.critic2.compile(optimizer=critic_optimizer, loss=clipped_error, metrics=critic_metrics)\n",
    "            self.target_critic2 = clone_model(self.critic2, self.custom_model_objects)\n",
    "            self.target_critic2.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "        # Combine actor and critic so that we can get the policy gradient.\n",
    "        # Assuming critic's state inputs are the same as actor's.\n",
    "        combined_inputs = []\n",
    "        state_inputs = []\n",
    "        for i in self.critic.inputs:\n",
    "            if i == self.critic_action_input:\n",
    "                combined_inputs.append([])\n",
    "            else:\n",
    "                combined_inputs.append(i)\n",
    "                state_inputs.append(i)\n",
    "        combined_inputs[self.critic_action_input_idx] = self.actor(state_inputs)\n",
    "\n",
    "        combined_output = self.critic(combined_inputs)\n",
    "        updates = actor_optimizer.get_updates(\n",
    "            params=self.actor.trainable_weights, loss=-K.mean(combined_output))\n",
    "        if self.target_model_update < 1.:\n",
    "            # Include soft target model updates.\n",
    "            updates += get_soft_target_model_updates(self.target_actor, self.actor, self.target_model_update)\n",
    "        updates += self.actor.updates  # include other updates of the actor, e.g. for BN\n",
    "\n",
    "        # Finally, combine it all into a callable function.\n",
    "        if K.backend() == 'tensorflow':\n",
    "            self.actor_train_fn = K.function(state_inputs + [K.learning_phase()],\n",
    "                                             [self.actor(state_inputs)], updates=updates)\n",
    "        else:\n",
    "            if True: #self.uses_learning_phase:\n",
    "                state_inputs += [K.learning_phase()]\n",
    "            self.actor_train_fn = K.function(state_inputs, [self.actor(state_inputs)], updates=updates)\n",
    "        self.actor_optimizer = actor_optimizer\n",
    "\n",
    "        self.compiled = True\n",
    "\n",
    "    def load_weights(self, filepath):\n",
    "        filename, extension = os.path.splitext(filepath)\n",
    "        actor_filepath = filename + '_actor' + extension\n",
    "        critic_filepath = filename + '_critic' + extension\n",
    "        self.actor.load_weights(actor_filepath)\n",
    "        self.critic.load_weights(critic_filepath)\n",
    "        self.update_target_models_hard()\n",
    "\n",
    "    def save_weights(self, filepath, overwrite=False):\n",
    "        filename, extension = os.path.splitext(filepath)\n",
    "        actor_filepath = filename + '_actor' + extension\n",
    "        critic_filepath = filename + '_critic' + extension\n",
    "        self.actor.save_weights(actor_filepath, overwrite=overwrite)\n",
    "        self.critic.save_weights(critic_filepath, overwrite=overwrite)\n",
    "\n",
    "    def update_target_models_hard(self):\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        if self.enable_twin_delay:\n",
    "            self.target_critic2.set_weights(self.critic2.get_weights())\n",
    "\n",
    "    # TODO: implement pickle\n",
    "\n",
    "    def reset_states(self):\n",
    "        if self.random_process is not None:\n",
    "            self.random_process.reset_states()\n",
    "        self.recent_action = None\n",
    "        self.recent_observation = None\n",
    "        if self.compiled:\n",
    "            self.actor.reset_states()\n",
    "            self.critic.reset_states()\n",
    "            self.target_actor.reset_states()\n",
    "            self.target_critic.reset_states()\n",
    "            if self.enable_twin_delay:\n",
    "                self.critic2.reset_states()\n",
    "                self.target_critic2.reset_states()\n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        batch = np.array(batch)\n",
    "        if self.processor is None:\n",
    "            return batch\n",
    "        return self.processor.process_state_batch(batch)\n",
    "\n",
    "    def forward(self, observation):\n",
    "        # Select an action.\n",
    "        state = self.memory.get_recent_state(observation)\n",
    "        batch = self.process_state_batch([state])\n",
    "        action = self.actor.predict_on_batch(batch).flatten()\n",
    "        assert action.shape == (self.nb_actions,)\n",
    "\n",
    "        if self.training:\n",
    "            action = self.policy.select_action(action, self.random_process,\n",
    "                                               noise_clip=None)\n",
    "\n",
    "        # Book-keeping.\n",
    "        self.recent_observation = observation\n",
    "        self.recent_action = action\n",
    "\n",
    "        return action\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return self.actor.layers[:] + self.critic.layers[:]\n",
    "\n",
    "    @property\n",
    "    def metrics_names(self):\n",
    "        names = self.critic.metrics_names[:]\n",
    "        if self.enable_twin_delay:\n",
    "            names += self.critic2.metrics_names[:]\n",
    "        if self.processor is not None:\n",
    "            names += self.processor.metrics_names[:]\n",
    "        return names\n",
    "\n",
    "    def backward(self, reward, terminal=False):\n",
    "        # Store most recent experience in memory.\n",
    "        if self.step % self.memory_interval == 0:\n",
    "            self.memory.append(self.recent_observation, self.recent_action, reward, terminal,\n",
    "                               training=self.training)\n",
    "\n",
    "        metrics = [np.nan for _ in self.metrics_names]\n",
    "        if not self.training:\n",
    "            # We're done here. No need to update the experience memory since we only use the working\n",
    "            # memory to obtain the state over the most recent observations.\n",
    "            return metrics\n",
    "\n",
    "        # Train the network on a single stochastic batch.\n",
    "        can_train_either = self.step > self.nb_steps_warmup_critic or self.step > self.nb_steps_warmup_actor\n",
    "        if can_train_either and self.step % self.train_interval == 0:\n",
    "            experiences = self.memory.sample(self.batch_size)\n",
    "            assert len(experiences) == self.batch_size\n",
    "\n",
    "            # Start by extracting the necessary parameters (we use a vectorized implementation).\n",
    "            state0_batch = []\n",
    "            reward_batch = []\n",
    "            action_batch = []\n",
    "            terminal1_batch = []\n",
    "            state1_batch = []\n",
    "            for e in experiences:\n",
    "                state0_batch.append(e.state0)\n",
    "                state1_batch.append(e.state1)\n",
    "                reward_batch.append(e.reward)\n",
    "                action_batch.append(e.action)\n",
    "                terminal1_batch.append(0. if e.terminal1 else 1.)\n",
    "\n",
    "            # Prepare and validate parameters.\n",
    "            state0_batch = self.process_state_batch(state0_batch)\n",
    "            state1_batch = self.process_state_batch(state1_batch)\n",
    "            terminal1_batch = np.array(terminal1_batch)\n",
    "            reward_batch = np.array(reward_batch)\n",
    "            action_batch = np.array(action_batch)\n",
    "            assert reward_batch.shape == (self.batch_size,)\n",
    "            assert terminal1_batch.shape == reward_batch.shape\n",
    "            assert action_batch.shape == (self.batch_size, self.nb_actions)\n",
    "\n",
    "            # Update critic, if warm up is over.\n",
    "            if self.step > self.nb_steps_warmup_critic:\n",
    "                target_actions = self.target_actor.predict_on_batch(state1_batch)\n",
    "                if self.enable_twin_delay:\n",
    "                    # Add clipped noise to target actions\n",
    "                    target_actions = self.policy.select_action(target_actions, noise_sigma=self.noise_sigma, noise_clip=self.noise_clip)\n",
    "                assert target_actions.shape == (self.batch_size, self.nb_actions)\n",
    "                if len(self.critic.inputs) >= 3:\n",
    "                    state1_batch_with_action = state1_batch[:]\n",
    "                else:\n",
    "                    state1_batch_with_action = [state1_batch]\n",
    "                state1_batch_with_action.insert(self.critic_action_input_idx, target_actions)\n",
    "                if self.enable_twin_delay:\n",
    "                    target_q1_values = self.target_critic.predict_on_batch(state1_batch_with_action).flatten()\n",
    "                    target_q2_values = self.target_critic2.predict_on_batch(state1_batch_with_action).flatten()\n",
    "                    target_q_values = np.minimum(target_q1_values, target_q2_values)\n",
    "                else:\n",
    "                    target_q_values = self.target_critic.predict_on_batch(state1_batch_with_action).flatten()\n",
    "                assert target_q_values.shape == (self.batch_size,)\n",
    "\n",
    "                # Compute r_t + gamma * max_a Q(s_t+1, a) and update the target ys accordingly,\n",
    "                # but only for the affected output units (as given by action_batch).\n",
    "                discounted_reward_batch = self.gamma * target_q_values\n",
    "                discounted_reward_batch *= terminal1_batch\n",
    "                assert discounted_reward_batch.shape == reward_batch.shape\n",
    "                targets = (reward_batch + discounted_reward_batch).reshape(self.batch_size, 1)\n",
    "\n",
    "                # Perform a single batch update on the critic network.\n",
    "                if len(self.critic.inputs) >= 3:\n",
    "                    state0_batch_with_action = state0_batch[:]\n",
    "                else:\n",
    "                    state0_batch_with_action = [state0_batch]\n",
    "                state0_batch_with_action.insert(self.critic_action_input_idx, action_batch)\n",
    "                metrics = self.critic.train_on_batch(state0_batch_with_action, targets)\n",
    "                if not isinstance(metrics, list):\n",
    "                    metrics = [metrics]\n",
    "                if self.enable_twin_delay:\n",
    "                    metrics2 = self.critic2.train_on_batch(state0_batch_with_action, targets)\n",
    "                    if not isinstance(metrics, list):\n",
    "                        metrics2 = [metrics2]\n",
    "                    metrics += metrics2\n",
    "                if self.processor is not None:\n",
    "                    metrics += self.processor.metrics\n",
    "\n",
    "            # Update actor, if warm up is over.\n",
    "            if self.step > self.nb_steps_warmup_actor and self.step % self.policy_delay == 0:\n",
    "                # TODO: implement metrics for actor\n",
    "                if len(self.actor.inputs) >= 2:\n",
    "                    inputs = state0_batch[:]\n",
    "                else:\n",
    "                    inputs = [state0_batch]\n",
    "                if True: #self.uses_learning_phase:\n",
    "                    inputs += [self.training]\n",
    "                action_values = self.actor_train_fn(inputs)[0]\n",
    "                assert action_values.shape == (self.batch_size, self.nb_actions)\n",
    "\n",
    "        if self.target_model_update >= 1 and self.step % self.target_model_update == 0:\n",
    "            self.update_target_models_hard()\n",
    "\n",
    "        return metrics\n",
    "\n",
    "class DDPGPolicy(Policy):\n",
    "    \"\"\"\n",
    "    Adds noise sampled from random_process to action.\n",
    "    If random_process is None, draws from N(0, noise_sigma) distribution.\n",
    "    If noise_clip is not None, clips noise to [-noise_clip, noise_clip]\n",
    "    \"\"\"\n",
    "    def select_action(self, action, random_process=None,\n",
    "                      noise_sigma=0.2, noise_clip=None):\n",
    "        if random_process is not None:\n",
    "            noise = random_process.sample()\n",
    "        else:\n",
    "            noise = np.random.normal(0, noise_sigma, action.shape)\n",
    "        if noise_clip is not None:\n",
    "            noise = np.clip(noise,\n",
    "                            -noise_clip * np.ones(noise.shape),\n",
    "                            noise_clip * np.ones(noise.shape))\n",
    "        assert noise.shape == action.shape\n",
    "        action += noise\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "devoted-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our DDPG agent\n",
    "\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta= 0.1, mu=0, sigma=.2)\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=action_input, batch_size=1024,\n",
    "                  memory=memory, nb_steps_warmup_critic=20, nb_steps_warmup_actor=20,\n",
    "                  random_process=random_process, gamma=0.95, target_model_update=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fluid-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.compile([Adam(lr=.0001, clipnorm=1.0), Adam(lr=.001, clipnorm=1.0)], metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "painted-satin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20000 steps ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "C:\\Users\\User\\.conda\\envs\\tfgpu\\lib\\site-packages\\rl\\memory.py:40: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow!!!\n",
      "   109/20000: episode: 1, duration: 22.625s, episode steps: 109, steps per second:   5, episode reward: -6.631, mean reward: -0.061 [-1.104,  0.005], mean action: -0.950 [-1.063, -0.815],  loss: 0.006786, mae: 0.071997, mean_q: -0.032555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\tfgpu\\lib\\site-packages\\rl\\memory.py:40: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slow!!!\n",
      "   643/20000: episode: 2, duration: 103.317s, episode steps: 534, steps per second:   5, episode reward: -2.676, mean reward: -0.005 [-1.101,  2.291], mean action: 0.469 [-0.944, 1.512],  loss: 0.009532, mae: 0.071978, mean_q: -0.055252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\tfgpu\\lib\\site-packages\\rl\\memory.py:40: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
      "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1209/20000: episode: 3, duration: 111.013s, episode steps: 566, steps per second:   5, episode reward: -8.419, mean reward: -0.015 [-1.030,  1.643], mean action: 0.648 [-0.758, 1.206],  loss: 0.006799, mae: 0.064175, mean_q: -0.189660\n",
      "  1769/20000: episode: 4, duration: 110.278s, episode steps: 560, steps per second:   5, episode reward: 18.285, mean reward:  0.033 [-0.994,  6.020], mean action: 0.136 [-1.165, 0.947],  loss: 0.010855, mae: 0.067189, mean_q: -0.169610\n",
      "  2769/20000: episode: 5, duration: 196.567s, episode steps: 1000, steps per second:   5, episode reward: -68.239, mean reward: -0.068 [-0.137,  2.276], mean action: 0.682 [-0.798, 1.562],  loss: 0.020758, mae: 0.086206, mean_q: -0.070457\n",
      "  3769/20000: episode: 6, duration: 194.738s, episode steps: 1000, steps per second:   5, episode reward: -27.922, mean reward: -0.028 [-0.112,  2.291], mean action: 0.301 [-1.029, 1.478],  loss: 0.015097, mae: 0.087539, mean_q: -0.010257\n",
      "  3956/20000: episode: 7, duration: 38.011s, episode steps: 187, steps per second:   5, episode reward:  5.621, mean reward:  0.030 [-0.992,  2.285], mean action: 0.125 [-1.125, 0.758],  loss: 0.013941, mae: 0.087110, mean_q: 0.006512\n",
      "  4706/20000: episode: 8, duration: 146.657s, episode steps: 750, steps per second:   5, episode reward: -12.535, mean reward: -0.017 [-0.993,  6.009], mean action: 0.055 [-1.017, 1.180],  loss: 0.016333, mae: 0.094069, mean_q: 0.042381\n",
      "  4936/20000: episode: 9, duration: 45.810s, episode steps: 230, steps per second:   5, episode reward:  3.175, mean reward:  0.014 [-0.998,  1.649], mean action: 0.149 [-0.782, 1.233],  loss: 0.022908, mae: 0.106151, mean_q: 0.079440\n",
      "  5163/20000: episode: 10, duration: 49.298s, episode steps: 227, steps per second:   5, episode reward:  5.977, mean reward:  0.026 [-0.992,  2.295], mean action: 0.001 [-1.196, 1.093],  loss: 0.021115, mae: 0.104529, mean_q: 0.086828\n",
      "  6163/20000: episode: 11, duration: 216.638s, episode steps: 1000, steps per second:   5, episode reward: -50.918, mean reward: -0.051 [-0.113,  2.294], mean action: 0.181 [-1.185, 1.452],  loss: 0.022341, mae: 0.108967, mean_q: 0.100343\n",
      "  6864/20000: episode: 12, duration: 147.627s, episode steps: 701, steps per second:   5, episode reward: 24.019, mean reward:  0.034 [-1.097,  6.016], mean action: 0.014 [-1.180, 1.076],  loss: 0.039194, mae: 0.134425, mean_q: 0.155735\n",
      "  7864/20000: episode: 13, duration: 193.400s, episode steps: 1000, steps per second:   5, episode reward: -45.794, mean reward: -0.046 [-0.116,  1.655], mean action: 0.303 [-0.853, 2.230],  loss: 0.046837, mae: 0.144128, mean_q: 0.189168\n",
      "done, took 1613.531 seconds\n"
     ]
    }
   ],
   "source": [
    "history = agent.fit(env, nb_steps=20000, visualize=True, verbose=2, nb_max_episode_steps=1000)\n",
    "episode_reward += history.history['episode_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "reverse-wages",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c16af57b50>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "horizontal-helping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c1042949a0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_reward = []\n",
    "sum_reward = 0\n",
    "span = 100\n",
    "for i in range(len(episode_reward)):\n",
    "    if i>=span: sum_reward -= episode_reward[i-span]\n",
    "    sum_reward += episode_reward[i]\n",
    "    if i>=span: avg_reward.append(sum_reward/span)\n",
    "plt.plot(avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "compact-bathroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c12bf63f40>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_reward = []\n",
    "sum_reward = 0\n",
    "span = 50\n",
    "for i in range(len(episode_reward)):\n",
    "    if i>=span: sum_reward -= episode_reward[i-span]\n",
    "    sum_reward += episode_reward[i]\n",
    "    if i>=span: avg_reward.append(sum_reward/span)\n",
    "plt.plot(avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "light-midwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c10773c520>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_reward = []\n",
    "sum_reward = 0\n",
    "span = 10\n",
    "for i in range(len(episode_reward)):\n",
    "    if i>=span: sum_reward -= episode_reward[i-span]\n",
    "    sum_reward += episode_reward[i]\n",
    "    if i>=span: avg_reward.append(sum_reward/span)\n",
    "plt.plot(avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.save_weights('ddpg_{}_weights.h5f'.format('32_3_rays_final'), overwrite=True)\n",
    "# actor.save_weights('actor_32_3_rays_final.h5', overwrite=True) \n",
    "# critic.save_weights('critic_32_3_rays_final.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.make_obstacles()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.sleep(10.)\n",
    "_ = agent.test(env, nb_episodes=50, visualize=True, nb_max_episode_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.load_weights('actor_32_3_rays_final.h5')\n",
    "critic.load_weights('critic_32_3_rays_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_weights('ddpg_{}_weights.h5f'.format('32_3_rays_final'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-silver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
